# 大数据知识图谱

## 概念

### 批处理 vs. 流处理

#### 批处理 Batching Processing

##### 有边界数据

###### 例如csv文件

##### 关心事件时间

##### 场景

###### 支付宝年度账单

###### 日志分析

###### 计费应用程序

###### 数据仓库聚合

#### 流处理 Streaming Processing

##### 无边界数据

##### 关心处理时间、或事件时间

##### 场景

###### 实时监控

###### 实时商业智能

######  POS 系统

##### 发布订阅模式

###### 区别于观察者模式（API调用）

###### 优点

####### 松耦合

####### 高伸缩性

####### 组件间通信更简洁

###### 缺点

####### 不能保证一定会送达

### Workflow System

#### 有向无环图 DAG: Directed Acyclic Graph

#### 四种设计模式

##### 复制模式 Copier

##### 过滤模式 Filter

##### 分离模式 Splitter

##### 合并模式 Joiner

## 思路

### 数据规模变大带来的问题

#### 内存占用

#### 磁盘IO延时

### 解决方案

#### 分而治之

## 框架

### MapReduce

#### 问题

##### 维护成本高

###### 要协调多个Map和多个Reduce任务

###### orchestration

##### 时间性能差

###### sharding不均衡，发生掉队者stragglers问题

### Hadoop

#### 组件

##### 数据存储层

###### HDFS

###### HBase

##### 数据处理层

###### 处理：MapReduce

###### 集群和资源管理：YARN

##### 数据访问层

###### Hive

###### Pig

###### Mahout

### FlumeJava

#### DAG 有向无环图

##### 节点：数据集

##### 边：数据变换

#### 优点

##### 无需复杂配置，自动进行性能优化

###### 合并重复数据处理流程

###### 计算资源的自动弹性分配

##### 把数据处理的描述语言与背后的运行引擎解耦

###### 有向图可作为`数据处理描述语言` 和 `运算引擎` 的前后端分离协议

##### 统一批处理与流处理的编程模型

###### 批处理：有界离散的数据

###### 流处理：无界连续的数据

##### 异常处理、数据监控

### Storm

### Spark

### Kafka

### Cloud Dataflow

### Flink

#### 批处理：DataSet

#### 流处理：DataStream

### Beam

## 架构

### Lambda架构

#### 组成

##### Batch Layer

###### 基于完整数据集重新计算

###### 能修复任何错误

##### Speed Layer

###### 实时处理新来的数据

###### 弥补批处理层锁导致的数据视图滞后

##### Serving Layer

###### 存储处理结果

###### 响应查询

#### 案例

##### Twitter hashtag分析

##### Smart Parking停车位推荐

#### 缺点

##### 维护复杂

###### 两个系统：批处理层，速度层

###### 要产生相同的结果输出到服务层

#### 通用架构图

### Kappa架构

#### 思路

##### 改进速度层性能，使得它可以处理好数据完整性和准确性问题

#### 过程

##### Kafka 设置日志保留期 （希望能够重新处理的历史数据时间区间）

##### 若要重新处理历史数据，则重新启动一个Kafka作业，offset=0

##### 新作业进度赶上旧数据视图后，切换到新视图读取

#### 缺点

##### 如果批处理和流处理逻辑不一样，则无法应用

##### 速度层异常处理

#### 架构图

## Spark

### 解决MapReduce痛点

#### 抽象层次低，需要开发大量底层逻辑

#### 只提供Map和Reduce两个操作

##### --> 多种操作，例如filter, map, group

#### Job计算结果存储在HDFS，延迟高

##### --> 中间结果存在内存

#### 只支持批处理，不支持流处理

### RDD

#### 基本数据结构 RDD

##### Resilient Distributed Dataset，弹性分布式数据集

##### 提供对RDD的各种操作

###### Transformation

####### map, filter, mapPartition, groupByKey

###### Action

####### collect, reduce, count, countByKey

##### 特点

###### 被分区

####### 同一个RDD包含的数据被存储在不同节点中

####### 标识：RDD ID + 分区index 

###### 不可变的

####### 一般通过转换，得到新的RDD

####### 好处：第N-1步出错，无需计算重复整个N步计算过程

###### 能够并行操作

####### 因为分区

#### 父子RDD的依赖关系

##### 窄依赖

###### 父RDD的分区可以一一对应到子RDD的分区

###### 例子：map, filter

###### 特点

####### 支持在同一个节点上链式执行多条命令

####### 窄依赖的失败恢复更有效

##### 宽依赖

###### 父RDD的分区可以被多个子RDD分区使用

###### join, groupBy

#### RDD 的存储

##### 存储级别

###### MEMORY_ONLY

###### MEMORY_AND_DISK

###### DISK_ONLY

###### MEMORY_ONLY_2 / DISK_ONLY_2

####### 每个分区在两个节点上建立副本

##### Checkpoint

###### 将耗时的RDD缓存至硬盘，标记其被检查点处理过，并清空其所有依赖关系

###### 当某个子RDD需要错误恢复时，回溯至该RDD 发现其被检查点记录过，则可以直接去硬盘读取，而无需再向前回溯

##### Iterator / Compute

###### 用来表示RDD怎样通过父RDD计算得到

###### 迭代函数

####### 先判断缓存中是否有想要的RDD

####### 再查找是否被checkpoint处理过

####### 否则调用compute向上递归，查找父RDD进行计算

##### persist() / cache()

将 RDD 的数据缓存至内存或硬盘中，这样当下次对同一 RDD 进行 Action 操作时，可以直接读取 RDD 的结果


### DataSet

#### 与RDD类似：转换和动作函数、延迟执行

#### 具有关系型表的特性：列、每列数据类型

##### 获取：people.name

### DataFrame

#### 一种特殊的DataSet

#### 提供类似SQL的查询接口

#### 每列并不存储类型信息

##### 获取：people.get As[String] ("name")

### 扩展库

#### Spark SQL: 支持结构化数据

#### Spark Streaming: 处理实时数据

#### MLlib: 用于机器学习

#### GraphX: 用于图计算

#### SparkR: 用于统计分析

## Spark Streaming

### 原理 

#### 类似微积分

#### 用时间片拆分无限的数据流，对每个数据片批处理

### DStream: 流数据抽象

#### 底层由多个序列化的RDD构成

#### 支持所有RDD的转换操作

#### 支持滑动窗口操作

##### window length

##### sliding interval

### 优点

#### 保持RDD的优良特性：数据容错、uyunxing速度

#### 与Spark SQL, MLib无缝集成

### 缺点

#### 延迟较高，1s

### 程序示例

```
//通过SparkConf 初始化SparkContext
conf = SparkConf()
.setAppName(appName)
.setMaster(master)

sc = SparkContext(conf=conf)

//SparkContext读取文件，创建一个RDD
text_file = sc.textFile("file://…...") 

```

#### SparkContext

Spark2.0之前

```
//通过SparkConf 初始化SparkContext
conf = SparkConf()
.setAppName(appName)
.setMaster(master)

sc = SparkContext(conf=conf)

//SparkContext读取文件，创建一个RDD
text_file = sc.textFile("file://…...") 

```

#### SparkSession

Spark2.0之后

```
spark = SparkSession
        .builder
        .appName(appName)
        .getOrCreate()
        
ds_lines = spark.read.textFile("file://….")
ds = ds_lines
.flatMap(lambda x: x.split(' '))
.groupBy("Value")
.count()

ds.show()

spark.stop()

```

### 对比Structured Streaming

#### Structured Streaming 无需构造RDD DAG执行图，更高层

#### Structured Stream基于Spark SQL引擎，性能更好

#### Structured Stream延迟更小， ms

#### Structured Stream对事件时间支持得更好

## 推荐系统

### 概念

#### 问题模式

##### 评分预测

###### RMSE 均方根误差

##### 行为预测

###### CTR 预估

#### 常见顽疾

##### 冷启动问题

##### 搜索与利用问题

###### Exploit

####### 对用户已经探明的兴趣加以利用

###### Explore

####### 探明用户还不知道的兴趣

##### 安全问题

## Tableau

### 工作区

#### Worksheet

#### Dashboard

#### Story

##### Worksheet、Dashboard的集合

#### Workbook

##### Worksheet、Dashboard、Story的集合

### 文件类型

#### 工作簿 .twb

##### 工作表、连接信息，不含数据

#### 打包工作簿 .twbx

##### twb + 本地资源

#### 数据源 .tds

##### 包含新建数据源所需的信息

#### 数据源 .tdsx

##### tds + 本地文件数据源

#### 书签 .tbm

##### 包含单个工作表

#### 数据提取 .tde

##### 数据源本地副本

### 参考

#### 中文文档

http://www.kubiji.cn/book/tableau/ 

#### 官方视频

https://www.tableau.com/learn/training?utm_campaign=Prospecting-CORE-ALL-ALL&utm_medium=Paid+Search&utm_source=Google+Search&utm_language=EN&utm_country=USCA&kw=&adgroup=CTX-Brand-Training-E&adused=&matchtype=e&placement=&kcid=c3617034-3f8e-41bd-90d5-2269c54da256&gclid=Cj0KEQjw9YTJBRD0vKClruOsuOwBEiQAGkQjP4HaLv9a5qcJDNHQDwGRp6ppd16Uoz1ZViq5cwcbwd8aAvcU8P8HAQ 
